{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AALnQO-y6HOz"
   },
   "source": [
    "# ***Reparameterization of the categorical distribution***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRc3KUnVPHm9"
   },
   "source": [
    "We will work with Torch throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hD0wA4YPFzy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Beta #, ...  import the distributions you need here\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x711bbc307fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSQ2cI-_QeEW"
   },
   "source": [
    "A helper function to visualize the generated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8U4TWTzs9KVd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def compare_samples (samples_1, samples_2, bins=10, range=None):\n",
    "  fig = plt.figure()\n",
    "  if range is not None:\n",
    "    plt.hist(samples_1, bins=bins, range=range)\n",
    "    plt.hist(samples_2, bins=bins, range=range)\n",
    "  else:\n",
    "    plt.hist(samples_1, bins=bins)\n",
    "    plt.hist(samples_2, bins=bins)\n",
    "  plt.xlabel('value')\n",
    "  plt.ylabel('number of samples')\n",
    "  plt.legend(['direct','via reparameterization'])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oSfkJfGAzNH"
   },
   "source": [
    "### ***Categorical Distribution***\n",
    "Below write a function that generates N samples from Categorical (**a**), where **a** = $[a_0, a_1, a_2, a_3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsBBxMRgBLIu"
   },
   "outputs": [],
   "source": [
    "def categorical_sampler(a, N):\n",
    "  # insert your code\n",
    "\n",
    "  return samples  # should be size N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZalUgMQTC68"
   },
   "source": [
    "Now write a function that generates samples from Categorical (**a**) via reparameterization:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxe9O-RIBSRN"
   },
   "outputs": [],
   "source": [
    "# Hint: approximate the Categorical distribution with the Gumbel-Softmax distribution\n",
    "def categorical_reparametrize(a, N, temp=0.1, eps=1e-20):  # temp and eps are hyperparameters for Gumbel-Softmax\n",
    "  # insert your code\n",
    "\n",
    "\n",
    "  return samples # make sure that your implementation allows the gradient to backpropagate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afyIAchkVVnh"
   },
   "source": [
    "Generate samples when $a = [0.1,0.2,0.5,0.2]$ and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxvilsshB7yS"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1,0.2,0.5,0.2])\n",
    "N = 1000\n",
    "direct_samples = categorical_sampler(a, N)\n",
    "reparametrized_samples = categorical_reparametrize(a, N, temp=0.1, eps=1e-20) # N x 4\n",
    "hard_samples = # convert reparametrized_samples to hard samples (shape N)\n",
    "compare_samples(direct_samples, hard_samples, bins=4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
